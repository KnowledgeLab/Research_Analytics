{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate_Html_and_Analysis_Data\n",
    "#\n",
    "# This ipython notebook is used to analysis the phi and theta from the Author Topic Model (c++)\n",
    "# And generate the html file for every research\n",
    "#\n",
    "# Dependency: json, pickle, numpy, scipy, csv, sklearn, string\n",
    "# \n",
    "# Input file: corpus_uchicago_small.tsv_phi (generate by the c++ code)\n",
    "#             corpus_uchicago_small.tsv_theta (generate by the c++ code)\n",
    "#             author_scopus_matches.csv (Used to find the author in uchicago scope)\n",
    "#\n",
    "# Output file: network json file\n",
    "#              personal html for every researcher\n",
    "#\n",
    "# Usage: Just go through this file\n",
    "#\n",
    "# Author: Cha Chen\n",
    "# Email: jamworld@uchicago.edu\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import all the dependency file\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import scipy as scp\n",
    "from scipy import stats\n",
    "import csv\n",
    "import sklearn\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "from sklearn.neighbors.ball_tree import BallTree\n",
    "from sklearn.cluster import KMeans\n",
    "from string import Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the phi and theta file into the TopicList and AuthorTopicList\n",
    "f = open(\"corpus_uchicago_small.tsv_phi\",'r')\n",
    "test = f.read()\n",
    "f.close()\n",
    "TopicList = [x.split('\\t') for x in test.split('\\n')]\n",
    "TopicList.remove([''])\n",
    "\n",
    "f = open(\"corpus_uchicago_small.tsv_theta\",'r')\n",
    "test = f.read()\n",
    "f.close()\n",
    "AuthorTopicList = [x.split('\\t') for x in test.split('\\n')]\n",
    "AuthorTopicList.remove([''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate the graph json file\n",
    "node = []\n",
    "link = []\n",
    "authorList = {}\n",
    "count = 0\n",
    "for author in AuthorTopicList:\n",
    "    if not authorList.get(author[0]):\n",
    "        authorList[author[0]] = count\n",
    "        count = count + 1\n",
    "        node.append({\n",
    "                \"id\": \"author_\" + author[0],\n",
    "                \"name\": \"author: \" + author[0],\n",
    "                \"type\": \"author\",\n",
    "                \"link\": author[0] + \".html\"\n",
    "            })\n",
    "    if float(author[2]) > 0.1:\n",
    "        link.append({\n",
    "                \"source\": \"author_\" + author[0],\n",
    "                \"target\": \"topic_\" + author[1],\n",
    "                \"prob\": float(author[2])\n",
    "            })\n",
    "topicList = {}\n",
    "wordList = {}\n",
    "count = 0\n",
    "for topic in TopicList:\n",
    "    if not topicList.get(topic[0]):\n",
    "        topicList[topic[0]] = count\n",
    "        count = count + 1\n",
    "        node.append({\n",
    "                \"id\": \"topic_\" + topic[0],\n",
    "                \"name\": \"topic: \" + topic[0],\n",
    "                \"type\": \"topic\",\n",
    "                \"link\": topic[0] + \".html\"\n",
    "            })\n",
    "    link.append({\n",
    "            \"source\": \"topic_\" + topic[0],\n",
    "            \"target\": \"word_\" + topic[1],\n",
    "            \"prob\": float(topic[2])\n",
    "        })\n",
    "    if not wordList.get(topic[1]):\n",
    "        wordList[topic[1]] = 1\n",
    "        node.append({\n",
    "                \"id\": \"word_\" + topic[1],\n",
    "                \"name\": \"word: \" + topic[1],\n",
    "                \"type\": \"words\",\n",
    "                \"link\": topic[1] + \".html\"\n",
    "            })\n",
    "        \n",
    "AuthorTopicData = {\"nodes\": node, \"links\": link}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write the json file\n",
    "f = open('AT-network.json','w')\n",
    "f.write(json.dumps(AuthorTopicData, sort_keys=True, indent=4))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build the Distribution Matrix here, used for knn and KL divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DisOfAuthorMatrix = np.zeros([len(authorList),100]) + 10**(-16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "authorMap = {}\n",
    "authorReverseMap = {}\n",
    "count = 0\n",
    "DisOfAuthorMatrix = np.zeros([len(authorList),100]) + 10**(-16)\n",
    "for author in AuthorTopicList:\n",
    "    if not author[0] in authorReverseMap:\n",
    "        authorMap[count] = author[0]\n",
    "        authorReverseMap[author[0]] = count\n",
    "        count = count + 1\n",
    "    DisOfAuthorMatrix[authorReverseMap[author[0]],int(author[1])] = float(author[2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the author Id map list\n",
    "authorIdMap = pickle.load(open('authorIdMapUChicago.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read the uchicago author id \n",
    "UChicagoScopus = {}\n",
    "with open('author_scopus_matches_hi.csv') as csvfile:\n",
    "    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "    for row in readCSV:\n",
    "        UChicagoScopus[row[6]] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find all the author in the uchciago scope\n",
    "aIdList = []\n",
    "for item in AuthorTopicList:\n",
    "    if UChicagoScopus.get(item[0]):\n",
    "        temp = []\n",
    "        temp.append(UChicagoScopus.get(item[0])[6])\n",
    "        temp.append(UChicagoScopus.get(item[0])[8])\n",
    "        temp.append(item[1])\n",
    "        temp.append(item[2])\n",
    "        aIdList.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build the network json for the first time, something needs to modify here\n",
    "# we will only use some of the mid-variable here\n",
    "node = []\n",
    "link = []\n",
    "authorList = {}\n",
    "count = 0\n",
    "for author in aIdList:\n",
    "    if not authorList.get(author[0]):\n",
    "        authorList[author[0]] = count\n",
    "        count = count + 1\n",
    "        node.append({\n",
    "                \"id\": \"author_\" + author[0],\n",
    "                \"name\": \"author: \" + author[1],\n",
    "                \"type\": \"author\",\n",
    "                \"link\": author[1] + \".html\"\n",
    "            })\n",
    "    if float(author[3]) > 0.1:\n",
    "        link.append({\n",
    "                \"source\": \"author_\" + author[0],\n",
    "                \"target\": \"topic_\" + author[2],\n",
    "                \"prob\": float(author[3])\n",
    "            })\n",
    "topicList = {}\n",
    "wordList = {}\n",
    "count = 0\n",
    "for topic in TopicList:\n",
    "    if not topicList.get(topic[0]):\n",
    "        topicList[topic[0]] = count\n",
    "        count = count + 1\n",
    "        node.append({\n",
    "                \"id\": \"topic_\" + topic[0],\n",
    "                \"name\": \"topic: \" + topic[0],\n",
    "                \"type\": \"topic\",\n",
    "                \"link\": topic[0] + \".html\"\n",
    "            })\n",
    "    link.append({\n",
    "            \"source\": \"topic_\" + topic[0],\n",
    "            \"target\": \"word_\" + topic[1],\n",
    "            \"prob\": float(topic[2])\n",
    "        })\n",
    "    if not wordList.get(topic[1]):\n",
    "        wordList[topic[1]] = 1\n",
    "        node.append({\n",
    "                \"id\": \"word_\" + topic[1],\n",
    "                \"name\": \"word: \" + topic[1],\n",
    "                \"type\": \"words\",\n",
    "                \"link\": topic[1] + \".html\"\n",
    "            })\n",
    "        \n",
    "AuthorTopicData = {\"nodes\": node, \"links\": link}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build the distribution matrix for the uchicago author\n",
    "DisOfAuthorMatrix = np.zeros([len(authorList),100]) + 10**(-16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "authorMap = {}\n",
    "authorReverseMap = {}\n",
    "count = 0\n",
    "DisOfAuthorMatrix = np.zeros([len(authorList),100]) + 10**(-16)\n",
    "for author in aIdList:\n",
    "    if not author[0] in authorReverseMap:\n",
    "        authorMap[count] = author[0]\n",
    "        authorReverseMap[author[0]] = count\n",
    "        count = count + 1\n",
    "    DisOfAuthorMatrix[authorReverseMap[author[0]],int(author[2])] = float(author[3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# caculate the sysmetry KL-divergence between all the researchers in the uchicago\n",
    "entropyMatAuthor = [[scp.stats.entropy(x,y)+scp.stats.entropy(y,x) for y in DisOfAuthorMatrix] for x in DisOfAuthorMatrix]\n",
    "simMatAuthor = [sorted(range(len(x)),key=lambda k: x[k]) for x in entropyMatAuthor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize an KNN model\n",
    "# set the cluster number to 100\n",
    "# total variation (TV) -> l1 norm\n",
    "kMN = KMeans(n_clusters=100, init='k-means++', n_init=10, max_iter=3000, tol=0.0001, precompute_distances='auto', verbose=0, random_state=None, copy_x=True, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(copy_x=True, init='k-means++', max_iter=3000, n_clusters=100,\n",
       "    n_init=10, n_jobs=1, precompute_distances='auto', random_state=None,\n",
       "    tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the knn model\n",
    "kMN.fit(DisOfAuthorMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/__main__.py:1: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "DisOfTopicMatrix = np.zeros([np.ceil(len(TopicList)/10),len(wordList)]) + 10**(-16)\n",
    "wordMap = {}\n",
    "wordReverseMap = {}\n",
    "count = 0\n",
    "for topic in TopicList:\n",
    "    if not wordMap.get(topic[1]):\n",
    "        wordMap[topic[1]] = count\n",
    "        wordReverseMap[count] = topic[1]\n",
    "        count = count + 1\n",
    "    DisOfTopicMatrix[int(topic[0]),wordMap[topic[1]]] = float(topic[2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build the real json file for the network\n",
    "# use the knn result to classify the reasearchers\n",
    "node = []\n",
    "link = []\n",
    "authorList = {}\n",
    "for author in aIdList:\n",
    "    if not authorList.get(author[0]):\n",
    "        authorList[author[0]] = 1\n",
    "        \n",
    "        node.append({\n",
    "                \"id\": \"author_\" + author[0],\n",
    "                \"name\": \"author: \" + author[1],\n",
    "                \"type\": \"author\",\n",
    "                \"link\": author[1] + \".html\",\n",
    "                \"cluster\": str(kMN.labels_[authorReverseMap[author[0]]])\n",
    "            })\n",
    "    if float(author[3]) > 0.1:\n",
    "        link.append({\n",
    "                \"source\": \"author_\" + author[0],\n",
    "                \"target\": \"topic_\" + author[2],\n",
    "                \"prob\": float(author[3])\n",
    "            })\n",
    "topicList = {}\n",
    "wordList = {}\n",
    "for topic in TopicList:\n",
    "    if not topicList.get(topic[0]):\n",
    "        topicList[topic[0]] = 1\n",
    "        node.append({\n",
    "                \"id\": \"topic_\" + topic[0],\n",
    "                \"name\": \"topic: \" + topic[0],\n",
    "                \"type\": \"topic\",\n",
    "                \"link\": topic[0] + \".html\"\n",
    "            })\n",
    "    link.append({\n",
    "            \"source\": \"topic_\" + topic[0],\n",
    "            \"target\": \"word_\" + topic[1],\n",
    "            \"prob\": float(topic[2])\n",
    "        })\n",
    "    if not wordList.get(topic[1]):\n",
    "        wordList[topic[1]] = 1\n",
    "        node.append({\n",
    "                \"id\": \"word_\" + topic[1],\n",
    "                \"name\": \"word: \" + topic[1],\n",
    "                \"type\": \"words\",\n",
    "                \"link\": topic[1] + \".html\"\n",
    "            })\n",
    "        \n",
    "AuthorTopicData = {\"nodes\": node, \"links\": link}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write the json file\n",
    "f = open('AT-network-UChicago.json','w')\n",
    "f.write(json.dumps(AuthorTopicData, sort_keys=True, indent=4))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in the author finger print page template\n",
    "f = open(\"template.txt\",'r')\n",
    "template = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = Template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build the reverse author hash table\n",
    "authorReverseList = {}\n",
    "for author in authorList:\n",
    "    authorReverseList[authorList[author]] = author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build the hash table for the template of the finger print page\n",
    "simAuthorSet = []\n",
    "for author in authorList:\n",
    "    authorPage = {}\n",
    "    authorIndex = authorReverseMap[author]\n",
    "    \n",
    "    # author's information\n",
    "    authorPage['author'] = UChicagoScopus.get(author)[8]\n",
    "    count = 0\n",
    "    for authorTopic in aIdList[(authorReverseMap[author])*10:((authorReverseMap[author])*10+10)]:\n",
    "        index = 'Topic' + str(count)\n",
    "        authorPage[index] = '\"Topic ' + authorTopic[2] + '\"'\n",
    "        index = 'Value' + str(count)\n",
    "        authorPage[index] = authorTopic[3]\n",
    "        count = count + 1\n",
    "    \n",
    "    # similiar author\n",
    "    for i in range(1,5):\n",
    "        index = 'simAuthor' + str(i)\n",
    "        authorPage[index] = UChicagoScopus.get(authorMap[simMatAuthor[authorIndex][i]])[8]\n",
    "        localIndex = authorMap[simMatAuthor[authorIndex][i]]\n",
    "        count = 0\n",
    "        for authorTopic in aIdList[(authorReverseMap[localIndex])*10:((authorReverseMap[localIndex])*10+10)]:\n",
    "            subIndex = 'Sim' + str(i) + 'Topic' + str(count)\n",
    "            authorPage[subIndex] = '\"Topic ' + authorTopic[2] + '\"'\n",
    "            subIndex = 'Sim' + str(i) + 'Value' + str(count)\n",
    "            authorPage[subIndex] = authorTopic[3]\n",
    "            count = count + 1\n",
    "        \n",
    "    simAuthorSet.append(authorPage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate all the html file\n",
    "for authorDataSet in simAuthorSet:\n",
    "    f = open('newHtml/'+ authorDataSet['author']+'.html','w')\n",
    "    f.write(s.substitute(authorDataSet))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
